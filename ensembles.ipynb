{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T16:05:49.468000Z",
     "start_time": "2018-03-11T16:05:48.184000Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# --- Importing libraries and creating import/export funcitons ------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import winsound\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from sklearn.linear_model import LogisticRegression as LRC\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "from sklearn.ensemble import BaggingClassifier as BAG\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ETC\n",
    "from mlxtend.classifier import EnsembleVoteClassifier as EVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Matplotlib Settings -------------------------------------------------------\n",
    "matplotlib.rc('figure', facecolor='k')\n",
    "style.use('dark_background')\n",
    "\n",
    "# --- Pandas Display Settings ---------------------------------------------------\n",
    "pd.options.display.width = 113\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.colheader_justify='right'\n",
    "\n",
    "# --- Importing Pickles from pre_ensmbles notebook ------------------------------\n",
    "def IMPORT_PICKLE(name):\n",
    "    '''\n",
    "    Returns pickled object within current file directory\n",
    "    '''\n",
    "    file_name = 'pickles/{}.pkl'.format(name)\n",
    "    with open(file_name, 'rb') as my_file:\n",
    "        return pickle.load(my_file)\n",
    "\n",
    "# Datasets\n",
    "X_u = IMPORT_PICKLE('unscaled_dataset')\n",
    "X_n = IMPORT_PICKLE('normalized_dataset')\n",
    "X_m = IMPORT_PICKLE('minmax_dataset')\n",
    "y = IMPORT_PICKLE('y')\n",
    "\n",
    "# Other\n",
    "feature_names = IMPORT_PICKLE('feature_names')\n",
    "ordi_dicts = IMPORT_PICKLE('ordinal_dicts') # helps in decoding ordinals\n",
    "set_names = IMPORT_PICKLE('names')\n",
    "clf_sets = IMPORT_PICKLE('best_clfs')\n",
    "cmatrix = IMPORT_PICKLE('matrices') # confusion matrix elements of all classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Finding ROC thresholds for each Classifier\n",
    "---\n",
    "### Definitions\n",
    "- `optimal`: closest to ideal classifier (TPR=1 and FPR=0)\n",
    "- `min cost`: yields minimum custom cost\n",
    "- `default`: default threshold\n",
    "- `max tpr @ min fpr`: yields maximum TPR possible given FPR is minimum\n",
    "- `min fpr @ max tpr`: yields minimum FPR possible given TPR is maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T16:24:40.904000Z",
     "start_time": "2018-03-11T16:24:38.708000Z"
    },
    "code_folding": [
     0,
     49,
     51,
     117,
     120,
     123,
     125
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SX_sig_n\n",
      "Missing default threshold was rectified for SX_sig_n\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGDCAYAAADEegxVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21412668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ve range: 0.918 to 1.053 | 532\n",
      "-ve range: 0.907 to 1.027 | 218\n",
      "number of unique thresholds: 750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>750</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>0.1989</td>\n",
       "      <td>0.3281</td>\n",
       "      <td>0.4294</td>\n",
       "      <td>0.5938</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <td>750</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>0.02156</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpr</th>\n",
       "      <td>750</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3369</td>\n",
       "      <td>0.6419</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fpr</th>\n",
       "      <td>750</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.1514</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.9954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>750</td>\n",
       "      <td>59.58</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>96</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>750</td>\n",
       "      <td>217.1</td>\n",
       "      <td>160.9</td>\n",
       "      <td>0</td>\n",
       "      <td>66.25</td>\n",
       "      <td>190.5</td>\n",
       "      <td>352.8</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>750</td>\n",
       "      <td>314.9</td>\n",
       "      <td>160.9</td>\n",
       "      <td>0</td>\n",
       "      <td>179.2</td>\n",
       "      <td>341.5</td>\n",
       "      <td>465.8</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>750</td>\n",
       "      <td>158.4</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>185</td>\n",
       "      <td>210</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost</th>\n",
       "      <td>750</td>\n",
       "      <td>-515</td>\n",
       "      <td>185.7</td>\n",
       "      <td>-1086</td>\n",
       "      <td>-547</td>\n",
       "      <td>-439.5</td>\n",
       "      <td>-390</td>\n",
       "      <td>-341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>750</td>\n",
       "      <td>0.6311</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.2907</td>\n",
       "      <td>0.5187</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count   mean     std    min    25%    50%    75%    max\n",
       "distance     750 0.6106  0.1989 0.3281 0.4294 0.5938 0.7778      1\n",
       "threshold    750 0.9957 0.02156 0.9068 0.9819 0.9985  1.011  1.053\n",
       "tpr          750  0.592  0.3024      0 0.3369 0.6419 0.8755      1\n",
       "fpr          750 0.2733  0.2826      0 0.0367 0.1514 0.4404 0.9954\n",
       "FP           750  59.58    61.6      0      8     33     96    217\n",
       "FN           750  217.1   160.9      0  66.25  190.5  352.8    532\n",
       "TP           750  314.9   160.9      0  179.2  341.5  465.8    532\n",
       "TN           750  158.4    61.6      1    122    185    210    218\n",
       "cost         750   -515   185.7  -1086   -547 -439.5   -390   -341\n",
       "accuracy     750 0.6311  0.1486 0.2907 0.5187  0.702 0.7587 0.7853"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>distance</th>\n",
       "      <th>threshold</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>cost</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "      <td>0</td>\n",
       "      <td>-1090</td>\n",
       "      <td>0.7093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>optimal</td>\n",
       "      <td>0.3281</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.1881</td>\n",
       "      <td>41</td>\n",
       "      <td>143</td>\n",
       "      <td>389</td>\n",
       "      <td>177</td>\n",
       "      <td>-348</td>\n",
       "      <td>0.7547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>min cost</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.7162</td>\n",
       "      <td>0.1743</td>\n",
       "      <td>38</td>\n",
       "      <td>151</td>\n",
       "      <td>381</td>\n",
       "      <td>180</td>\n",
       "      <td>-341</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max tpr @ min fpr</td>\n",
       "      <td>0.906</td>\n",
       "      <td>1.027</td>\n",
       "      <td>0.09398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>50</td>\n",
       "      <td>218</td>\n",
       "      <td>-482</td>\n",
       "      <td>0.3573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>min fpr @ max tpr</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "      <td>1</td>\n",
       "      <td>-1085</td>\n",
       "      <td>0.7107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         description  distance  threshold     tpr    fpr  FP  FN  TP  TN  cost  accuracy\n",
       "0            default         1     0.9068       1      1 218   0 532   0 -1090    0.7093\n",
       "1            optimal    0.3281     0.9939  0.7312 0.1881  41 143 389 177  -348    0.7547\n",
       "2           min cost    0.3331     0.9952  0.7162 0.1743  38 151 381 180  -341     0.748\n",
       "3  max tpr @ min fpr     0.906      1.027 0.09398      0   0 482  50 218  -482    0.3573\n",
       "4  min fpr @ max tpr    0.9954     0.9068       1 0.9954 217   0 532   1 -1085    0.7107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Find Threshold Routine and Sample Output ----------------------------------\n",
    "def FIND_THRESHOLDS(clf_name, clf, X_train, y_train, expt=False, show=False):\n",
    "    '''\n",
    "    [Description]\n",
    "    -----------------------------------------------------------------------------\n",
    "    Computes ROC curve of a binary classifier and identifies unique thresholds \n",
    "    such as:\n",
    "    > the default threshold\n",
    "    > the optimal threshold\n",
    "    > the threshold yielding minimal cost\n",
    "    > the threshold yielding max tpr at min fpr\n",
    "    > the threshold yielding min fpr at max tpr\n",
    "    \n",
    "    [Inputs]\n",
    "    -----------------------------------------------------------------------------\n",
    "    ________\n",
    "    clf_name|   [string]\n",
    "                Name of the classifier\n",
    "    ________\n",
    "    clf     |   [sklearn classifier object]\n",
    "                The classifier object. Must have either predict_proba() or\n",
    "                decision_function() method\n",
    "    ________\n",
    "    X_train |   [numpy array]\n",
    "                The training/validation data for the classifier. Used to compute\n",
    "                thresholds with the predict_proba() or decision_funciton() method\n",
    "    ________\n",
    "    y_train |   [numpy array]\n",
    "                The training/validation label for the classifier. Used to compute\n",
    "                the confusion metrix at each unique threshold\n",
    "    ________\n",
    "    expt    |   [boolean] Default = False\n",
    "                Wether to use the predict_proba() method or not. If false then\n",
    "                decision_function() method is used to compute thresholds\n",
    "    ________\n",
    "    show    |   [boolean] Default = False\n",
    "                Wether to plot the ROC curve (with important thresholds marked)\n",
    "                and to show threshold ranges for the +ve and -ve class\n",
    "                \n",
    "    [Outputs]\n",
    "    -----------------------------------------------------------------------------\n",
    "    ________\n",
    "    IT      |   [pandas DataFrame]\n",
    "                Contains only important thresholds' data\n",
    "    ________\n",
    "    roc     |   [pandas DataFrame]\n",
    "                Contains all thresholds' data. Useful for assessing summary stats\n",
    "    '''\n",
    "    \n",
    "    if expt == False:\n",
    "        prob_train = clf.predict_proba(X_train)[:, 1].tolist()\n",
    "    else:\n",
    "        prob_train = clf.decision_function(X_train).tolist()\n",
    "    \n",
    "    pred_probs = pd.Series(data=prob_train)\n",
    "    \n",
    "    # Stores unique thresholds\n",
    "    probs = pred_probs.unique().tolist()\n",
    "    probs.sort()\n",
    "    \n",
    "    # Stores threshold data: distance, tpr, fpr, confusion matrix, cost, accuracy\n",
    "    roc_curve_vals = []\n",
    "    \n",
    "    # IT: Important Thresholds\n",
    "    IT = []\n",
    "    \n",
    "    # Default threshold criterias\n",
    "    cm = pd.DataFrame(metrics.confusion_matrix(y_train,\n",
    "                                               clf.predict(X_train)),\n",
    "                      columns = ['pred -ve', 'pred +ve'],\n",
    "                      index = ['actual -ve', 'actual +ve'])\n",
    "    dcTP = cm.loc['actual +ve', 'pred +ve']\n",
    "    dcTN = cm.loc['actual -ve', 'pred -ve']\n",
    "    dcFN = cm.loc['actual +ve', 'pred -ve']\n",
    "    dcFP = cm.loc['actual -ve', 'pred +ve']\n",
    "    \n",
    "    # Computing data for each unique thrshold\n",
    "    for threshold in probs:\n",
    "        \n",
    "        # Shifting the threshold in predictions\n",
    "        thresholded_y_pred = np.where(pred_probs.values > threshold, 1, 0)\n",
    "        \n",
    "        # Computing the confusion matrix of the new predictions\n",
    "        cm = pd.DataFrame(metrics.confusion_matrix(y_train, thresholded_y_pred),\n",
    "                          columns = ['pred -ve', 'pred +ve'],\n",
    "                          index = ['actual -ve', 'actual +ve'])\n",
    "        TP = cm.loc['actual +ve', 'pred +ve'] # True positive\n",
    "        TN = cm.loc['actual -ve', 'pred -ve'] # True negative\n",
    "        FN = cm.loc['actual +ve', 'pred -ve'] # False negative\n",
    "        FP = cm.loc['actual -ve', 'pred +ve'] # False positive\n",
    "        \n",
    "        TPR = TP/float(TP+FN) # True positive rate\n",
    "        FPR = FP/float(FP+TN) # False negative rate\n",
    "        \n",
    "        # Distance from best possible classifier (Pythagoras' theorem)\n",
    "        d = ((1-TPR)**2 + FPR**2) ** 0.5\n",
    "        \n",
    "        # Custom cost fuction (negated as convetion dictates it)\n",
    "        cost = -1*((FP*5)+FN)\n",
    "        \n",
    "        # Accuracy\n",
    "        ACC = (TP+TN)/float(len(y_train))\n",
    "        \n",
    "        # Appending results\n",
    "        roc_curve_vals.append([d, threshold, TPR, FPR, FP, FN, TP, TN, cost, ACC])\n",
    "        \n",
    "        # Checking if the current threshold is the default thrshold\n",
    "        if (TP==dcTP) & (TN==dcTN) & (FN==dcFN) & (FP==dcFP):\n",
    "            \n",
    "            # If true, save to IT\n",
    "            IT.append(['default', d, threshold, TPR, FPR,\n",
    "                       FP, FN, TP, TN, cost, ACC])\n",
    "    \n",
    "    # Checking for possible default threshold duplicates\n",
    "    if len(IT) > 1:\n",
    "        print 'Decuplicate default thresholds found in {}'.format(clf_name)\n",
    "        # Checking if thresholds are probabilities or scores\n",
    "        if expt == False:\n",
    "            # If score then the default threshold is the one closest to 0\n",
    "            IT = IT.iloc[IT['threshold'].abs().argsort()[:1]]\n",
    "        else:\n",
    "            # If probs then the default threshold is the one closest to 0.5\n",
    "            IT = IT.iloc[(IT['threshold']-0.5).abs().argsort()[:1]]\n",
    "    elif len(IT) == 0:\n",
    "        print 'Missing default threshold was rectified for {}'.format(clf_name)\n",
    "        for threshold in probs:\n",
    "        \n",
    "            # Shifting the threshold in predictions\n",
    "            thresholded_y_pred = np.where(pred_probs.values >= threshold, 1, 0)\n",
    "\n",
    "            # Computing the confusion matrix of the new predictions\n",
    "            cm = pd.DataFrame(metrics.confusion_matrix(y_train, thresholded_y_pred),\n",
    "                              columns = ['pred -ve', 'pred +ve'],\n",
    "                              index = ['actual -ve', 'actual +ve'])\n",
    "            TP = cm.loc['actual +ve', 'pred +ve'] # True positive\n",
    "            TN = cm.loc['actual -ve', 'pred -ve'] # True negative\n",
    "            FN = cm.loc['actual +ve', 'pred -ve'] # False negative\n",
    "            FP = cm.loc['actual -ve', 'pred +ve'] # False positive\n",
    "\n",
    "            TPR = TP/float(TP+FN) # True positive rate\n",
    "            FPR = FP/float(FP+TN) # False negative rate\n",
    "\n",
    "            # Distance from best possible classifier (Pythagoras' theorem)\n",
    "            d = ((1-TPR)**2 + FPR**2) ** 0.5\n",
    "\n",
    "            # Custom cost fuction (negated as convetion dictates it)\n",
    "            cost = -1*((FP*5)+FN)\n",
    "\n",
    "            # Accuracy\n",
    "            ACC = (TP+TN)/float(len(y_train))\n",
    "\n",
    "            # Checking if the current threshold is the default thrshold\n",
    "            if (TP==dcTP) & (TN==dcTN) & (FN==dcFN) & (FP==dcFP):\n",
    "\n",
    "                # If true, save to IT\n",
    "                IT.append(['default', d, threshold, TPR, FPR,\n",
    "                           FP, FN, TP, TN, cost, ACC])\n",
    "    \n",
    "    # Turning roc_curve_vals data into a dataframe with proper column names\n",
    "    roc = pd.DataFrame(data=roc_curve_vals,\n",
    "                       columns=['distance','threshold', 'tpr', 'fpr',\n",
    "                                'FP', 'FN', 'TP', 'TN', 'cost', 'accuracy'])\n",
    "    \n",
    "    # Finding optimal threshold (minimum distance to best classifier)\n",
    "    optimal = roc.sort_values(['distance']).iloc[:1].values.tolist()\n",
    "    IT.append(['optimal']+optimal[0])\n",
    "    \n",
    "    # Finding threshold at which cost function is minimal\n",
    "    min_cost = roc.sort_values(['cost'], ascending=False).iloc[:1].values.tolist()\n",
    "    IT.append(['min cost']+min_cost[0])\n",
    "    \n",
    "    # Finding threshold at which TPR is max when FPR is min\n",
    "    fpr = roc['fpr'].values.tolist()\n",
    "    max_tpr = roc[roc['fpr']==min(fpr)].sort_values(['tpr'], ascending=False).iloc[:1].values.tolist()\n",
    "    IT.append(['max tpr @ min fpr']+max_tpr[0])\n",
    "    \n",
    "    # Finding threshols at which FPR is min when TPR is max\n",
    "    tpr = roc['tpr'].values.tolist()\n",
    "    min_fpr = roc[roc['tpr']==max(tpr)].sort_values(['fpr']).iloc[:1].values.tolist()\n",
    "    IT.append(['min fpr @ max tpr']+min_fpr[0])\n",
    "    \n",
    "    # Turning IT data into a dataframe with proper column names\n",
    "    IT = pd.DataFrame(data=IT, columns=['description', 'distance', 'threshold', \n",
    "                                        'tpr', 'fpr', 'FP', 'FN', 'TP', 'TN', \n",
    "                                        'cost', 'accuracy'])\n",
    "    \n",
    "    if show:\n",
    "        \n",
    "        # Plotting ROC curve with important thresholds plotted onto it\n",
    "        fig = plt.figure(figsize=[6, 6])\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.plot(fpr, tpr, c='r', label=clf_name) # Classifier ROC Curve\n",
    "        plt.scatter(IT[IT['description']=='optimal'].values.tolist()[0][4],\n",
    "                    IT[IT['description']=='optimal'].values.tolist()[0][3],\n",
    "                    marker='*', s=150, color='lime', label = 'optimal')\n",
    "        plt.scatter(IT[IT['description']=='min cost'].values.tolist()[0][4],\n",
    "                    IT[IT['description']=='min cost'].values.tolist()[0][3],\n",
    "                    marker='p', s=150, color='y', label = 'min cost')\n",
    "        plt.scatter(IT[IT['description']=='default'].values.tolist()[0][4],\n",
    "                    IT[IT['description']=='default'].values.tolist()[0][3],\n",
    "                    marker='X', s=100, color='orange', label = 'default')\n",
    "        plt.scatter(IT[IT['description']=='max tpr @ min fpr'].values.tolist()[0][4],\n",
    "                    IT[IT['description']=='max tpr @ min fpr'].values.tolist()[0][3],\n",
    "                    marker='_', s=150, color='w', label = 'max tpr @ min fpr')\n",
    "        plt.scatter(IT[IT['description']=='min fpr @ max tpr'].values.tolist()[0][4],\n",
    "                    IT[IT['description']=='min fpr @ max tpr'].values.tolist()[0][3],\n",
    "                    marker='|', s=150, color='w', label = 'min fpr @ max tpr')\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator(10))\n",
    "        ax.yaxis.set_minor_locator(AutoMinorLocator(10))\n",
    "        plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.grid(which='major', alpha=0.3)\n",
    "        plt.grid(which='minor', alpha=0.1)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positibe Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        max_TPR = IT[IT['description']=='max tpr @ min fpr'].values.tolist()[0][3]\n",
    "        min_FPR = IT[IT['description']=='min fpr @ max tpr'].values.tolist()[0][4]\n",
    "        plt.xlim([-0.02, round(min_FPR+0.05, 1)+0.02])\n",
    "        plt.ylim([round(max_TPR-0.05, 1)-0.02, 1.02])\n",
    "        plt.legend(loc=4)\n",
    "        plt.show()\n",
    "        \n",
    "        # Printing threshold ranges for the +ve class and -ve class\n",
    "        label = pd.Series(data=y_train)\n",
    "        prob_label = pd.concat([label, pred_probs], axis=1, ignore_index=True)\n",
    "        prob_label.columns = ['label', 'prob']\n",
    "        pos = prob_label[prob_label['label']==1].iloc[:,1].sort_values()\n",
    "        neg = prob_label[prob_label['label']==0].iloc[:,1].sort_values()\n",
    "        pos_count = pos.value_counts().sort_index()\n",
    "        neg_count = neg.value_counts().sort_index()\n",
    "        pos = pos.values.tolist()\n",
    "        neg = neg.values.tolist()\n",
    "        n_pos = len(pos_count)\n",
    "        n_neg = len(neg_count)\n",
    "        print '+ve range: {:.3f} to {:.3f} | {}'.format(min(pos), max(pos), n_pos)\n",
    "        print '-ve range: {:.3f} to {:.3f} | {}'.format(min(neg), max(neg), n_neg)\n",
    "    \n",
    "    return IT, roc\n",
    "\n",
    "# Sample Output\n",
    "set_ = 3\n",
    "n = 6\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_n, y, random_state=2018)\n",
    "clf = clf_sets[set_][n]\n",
    "clf_name  = clf_sets[set_].index[n]\n",
    "print clf_name\n",
    "res, roc = FIND_THRESHOLDS(clf_name, clf, X_train, y_train, expt=True, show=True)\n",
    "\n",
    "pd.options.display.float_format = '{:.4g}'.format\n",
    "print 'number of unique thresholds:', len(roc['threshold'].values.tolist())\n",
    "display(roc.describe().T)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-03T01:47:26.458000Z",
     "start_time": "2018-03-03T01:45:20.904000Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing default threshold was rectified for SX_sig_n_imb_roc\n",
      "Missing default threshold was rectified for SX_sig_m_imb_roc\n",
      "Missing default threshold was rectified for GB_exp_u_bal_cus\n",
      "Missing default threshold was rectified for RB_gin_u_imb_roc\n",
      "\n",
      ">>> Statistical summary of thresholds:\n",
      "          count   mean    std   min    25%    50%    75%  max\n",
      "cost        800 -218.8  86.21  -410 -252.2   -175   -161 -140\n",
      "accuracy    800 0.6127 0.1285 0.328  0.584  0.676  0.696 0.76\n",
      "tpr         800 0.6052 0.3142     0 0.4807 0.6726 0.8512    1\n",
      "fpr         800 0.3719 0.3159     0 0.1707 0.3049 0.5366    1\n",
      "FP          800  30.49   25.9     0     14     25     44   82\n",
      "FN          800  66.33  52.78     0     25     55  87.25  168\n",
      "TP          800  101.7  52.78     0  80.75    113    143  168\n",
      "TN          800  51.51   25.9     0     38     57     68   82\n"
     ]
    }
   ],
   "source": [
    "# --- Assessing all Classifiers at Important Thresholds Individually ------------\n",
    "\n",
    "def TEST_THRESHOLD(clf, threshold, X_test, y_test, expt=False):\n",
    "    '''\n",
    "    [Description]\n",
    "    -----------------------------------------------------------------------------\n",
    "    Computes True Positive Rate, False Positive Rate, confusion matrix elemets,\n",
    "    custom cost and accuracy of a trained classifier for a specified threshold \n",
    "    using the hold-out set\n",
    "    \n",
    "    [Inputs]\n",
    "    -----------------------------------------------------------------------------\n",
    "    _________\n",
    "    clf      |  [sklearn classifier object]\n",
    "                The classifier object. Must have either predict_proba() or\n",
    "                decision_function() method\n",
    "    _________\n",
    "    threshold|  [float]\n",
    "                The threshold value to shift predictions with\n",
    "    _________\n",
    "    X_test   |  [numpy array]\n",
    "                Hold-out set feature data to test classifier with\n",
    "    _________\n",
    "    y_test   |  [numpy array]\n",
    "                Hold-out set lebals to use to assess validity of predictions with\n",
    "    ________\n",
    "    expt    |   [boolean] Default = False\n",
    "                Wether to use the predict_proba() method or not. If false then\n",
    "                decision_function() method is used to compute thresholds\n",
    "    [Outputs]\n",
    "    -----------------------------------------------------------------------------\n",
    "    ________\n",
    "    res     |   [list]\n",
    "                List containing the following in this order:\n",
    "                > Custom cost score\n",
    "                > Accuracy\n",
    "                > True Positive Rate\n",
    "                > False Positive Rate\n",
    "                > Number of FP\n",
    "                > Number of FN\n",
    "                > Number of TP\n",
    "                > Number of TN\n",
    "    '''\n",
    "    \n",
    "    # Obtaining predition probabilities/scores\n",
    "    if expt == False:\n",
    "        prob_train = clf.predict_proba(X_test)[:, 1].tolist()\n",
    "    else:\n",
    "        prob_train = clf.decision_function(X_test).tolist()\n",
    "    pred_probs = pd.Series(data=prob_train)\n",
    "    \n",
    "    # Shifting the threshold in predictions\n",
    "    thresholded_y_pred = np.where(pred_probs.values > threshold, 1, 0)\n",
    "        \n",
    "    # Computing the confusion matrix of the new thresholded predictions\n",
    "    cm = pd.DataFrame(metrics.confusion_matrix(y_test, thresholded_y_pred),\n",
    "                      columns = ['pred -ve', 'pred +ve'],\n",
    "                      index = ['actual -ve', 'actual +ve'])\n",
    "    TP = cm.loc['actual +ve', 'pred +ve'] # True positive\n",
    "    TN = cm.loc['actual -ve', 'pred -ve'] # True negative\n",
    "    FN = cm.loc['actual +ve', 'pred -ve'] # False negative\n",
    "    FP = cm.loc['actual -ve', 'pred +ve'] # False positive\n",
    "    TPR = TP/float(TP+FN) # True positive rate\n",
    "    FPR = FP/float(FP+TN) # False negative rate\n",
    "        \n",
    "    # Custom cost fuction (negated as convetion dictates it)\n",
    "    cost = -1*((FP*5)+FN)\n",
    "        \n",
    "    # Accuracy\n",
    "    ACC = (TP+TN)/float(len(y_test))\n",
    "    \n",
    "    # Results\n",
    "    res = [cost, ACC, TPR, FPR, FP, FN, TP, TN]\n",
    "    \n",
    "    return res\n",
    "\n",
    "# Threshold search results (cost and accuracy scores based on train set)\n",
    "TH_find_res = []\n",
    "\n",
    "# Important thresholds test results\n",
    "IT_test_res = []\n",
    "\n",
    "# Classifier names\n",
    "names = []\n",
    "\n",
    "# Classifier name + threshold name\n",
    "clf_threshold_names = []\n",
    "\n",
    "for i in range(0, len(clf_sets)):\n",
    "    \n",
    "    # Feature scaling requirements for each group of classifiers\n",
    "    if i < 4:\n",
    "        X = X_n # Normalized scaling\n",
    "    elif i < 8:\n",
    "        X = X_m # MinMax scaling\n",
    "    else:\n",
    "        X = X_u # Unscaled features\n",
    "    \n",
    "    # Creating training and testing features and labels\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2018)\n",
    "    \n",
    "    for j in range(0, len(clf_sets[i])):\n",
    "        \n",
    "        # Finding important thresholds\n",
    "        clf = clf_sets[i][j]\n",
    "        name = '{}_{}{}'.format(clf_sets[i].index[j], \n",
    "                                set_names[i][0:4], \n",
    "                                set_names[i][6:])\n",
    "        names.append(name)\n",
    "        if name[0:1] in ('D', 'R', 'E'): # DT, RFC & ETC have only predict_proba\n",
    "            IT, roc = FIND_THRESHOLDS(name, clf, X_train, y_train, expt=False)\n",
    "        else:\n",
    "            IT, roc = FIND_THRESHOLDS(name, clf, X_train, y_train, expt=True)\n",
    "        TH_find_res.append([IT, roc]) # Saving for future referece\n",
    "        \n",
    "        # Computing number of unique thresholds\n",
    "        n_thres = len(roc['threshold'].values.tolist()) # bad when low\n",
    "        \n",
    "        # Important threshold names\n",
    "        IT_names = ['def', # default threshold \n",
    "                    'opt', # optimal threshold\n",
    "                    'min', # min cost\n",
    "                    'tpr', # max tpr @ min fpr\n",
    "                    'fpr'] # min fpr @ max tpr\n",
    "        \n",
    "        # Assessing performance of each individual threshold\n",
    "        thresholds = IT['threshold'].values.tolist()\n",
    "        for k, threshold in enumerate(thresholds):\n",
    "            if name[0:1] in ('D', 'R', 'E'):\n",
    "                res = TEST_THRESHOLD(clf, threshold, X_test, y_test, expt=False)\n",
    "            else:\n",
    "                res = TEST_THRESHOLD(clf, threshold, X_test, y_test, expt=True)\n",
    "                \n",
    "            # Constructing the names\n",
    "            clf_threshold_names.append('{}_{}'.format(name, IT_names[k]))\n",
    "            \n",
    "            # Appending testing results \n",
    "            IT_test_res.append(res)\n",
    "\n",
    "TH_find_res = pd.DataFrame(data=TH_find_res, columns=['IT', 'roc'], index=names)\n",
    "IT_test_res = pd.DataFrame(data=IT_test_res, index=clf_threshold_names,\n",
    "                           columns=['cost', 'accuracy', 'tpr', 'fpr',\n",
    "                                    'FP', 'FN', 'TP', 'TN'])\n",
    "\n",
    "# Displaying summaries\n",
    "print '\\n>>> Statistical summary of thresholds:'\n",
    "print IT_test_res.describe().T\n",
    "\n",
    "winsound.Beep(1800,50); winsound.Beep(1500,75); winsound.Beep(1200,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-03T07:33:21.409000Z",
     "start_time": "2018-03-03T07:33:21.374000Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Top 5 with max accuracy then min cost then max tpr:\n",
      "                      cost  accuracy    tpr    fpr  FP  FN   TP  TN\n",
      "SL_l2s_n_imb_roc_def  -212      0.76  0.869 0.4634  38  22  146  44\n",
      "LR_l2s_m_imb_roc_def  -228      0.76 0.8929 0.5122  42  18  150  40\n",
      "LR_l2l_m_imb_roc_def  -228      0.76 0.8929 0.5122  42  18  150  40\n",
      "LR_nwt_m_imb_roc_def  -228      0.76 0.8929 0.5122  42  18  150  40\n",
      "LR_lbf_m_imb_roc_def  -228      0.76 0.8929 0.5122  42  18  150  40\n",
      "LR_sag_m_imb_roc_def  -228      0.76 0.8929 0.5122  42  18  150  40\n",
      "LR_sag_m_imb_cus_def  -213     0.756 0.8631 0.4634  38  23  145  44\n",
      "LR_l1s_m_imb_roc_def  -217     0.756  0.869 0.4756  39  22  146  43\n",
      "LR_l1l_m_imb_roc_def  -217     0.756  0.869 0.4756  39  22  146  43\n",
      "SL_l1s_n_imb_roc_def  -225     0.756  0.881    0.5  41  20  148  41\n"
     ]
    }
   ],
   "source": [
    "# --- Best Stand Alone Models' Results ------------------------------------------\n",
    "print '>>> Top 5 with max accuracy then min cost then max tpr:'\n",
    "print IT_test_res.sort_values(['accuracy', 'cost', 'tpr'], \n",
    "                              ascending=[False, False, False]).head(10)\n",
    "\n",
    "# Storing threhsolds and confidence scoring methods for each classifier\n",
    "# Harvesting the thresholds\n",
    "thresholds = []\n",
    "for i in range(0, len(TH_find_res)):\n",
    "    thresholds.append(TH_find_res.iloc[i,0].iloc[:,2].values.tolist()) \n",
    "thresholds = pd.DataFrame(data=thresholds, index=TH_find_res.index.tolist(),\n",
    "                          columns=['def', 'opt', 'min', 'tpr', 'fpr'])\n",
    "index = thresholds.index.tolist()\n",
    "\n",
    "# Harvesting classifiers from clf_sets\n",
    "clfs = []\n",
    "for i in range(0, len(clf_sets)):\n",
    "    for j in range(0, len(clf_sets[i])):\n",
    "        clfs.append(clf_sets[i][j])\n",
    "clfs = pd.DataFrame(data=clfs, columns=['classifier'], index=index)\n",
    "\n",
    "# Identifying the confidence scoring methods\n",
    "method = []\n",
    "for i in index:\n",
    "    if i[:1] in ('G', 'L', 'S'):\n",
    "        method.append('decision_funtion')\n",
    "    else:\n",
    "        method.append('predict_proba')\n",
    "method = pd.DataFrame(data=method, columns=['method'], index=index)\n",
    "\n",
    "# Final Dataframe containing both the confidence scoring method and thresholds\n",
    "METH = pd.concat([method, thresholds, clfs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T10:00:16.599000Z",
     "start_time": "2018-03-04T10:00:16.551000Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.03321495337607938, class_weight='balanced', dual=False,\n",
      "     fit_intercept=False, intercept_scaling=1, loss='squared_hinge',\n",
      "     max_iter=1000, multi_class='ovr', penalty='l1', random_state=2018,\n",
      "     tol=0.0001, verbose=0)\n",
      "[-0.0027807332864267092, -0.1425517556169695, 0.20895454834625446, 0.6514328961039345, -1.0709525044337047]\n",
      "decision_funtion\n",
      "   def  opt  min  tpr  fpr  sum  V2  V3  V4\n",
      "0    1    1    1    0    1    4   1   1   1\n",
      "1    1    1    1    1    1    5   1   1   1\n",
      "2    0    0    0    0    1    1   0   0   0\n",
      "3    1    1    0    0    1    3   1   1   0\n",
      "4    0    0    0    0    1    1   0   0   0\n"
     ]
    }
   ],
   "source": [
    "# --- Threshold Voting Helper Function ------------------------------------------\n",
    "def THRESHOLD_VOTING(clf, thresholds, method, X_test, y_test):\n",
    "    '''\n",
    "    [Description]\n",
    "    -----------------------------------------------------------------------------\n",
    "    Conducts a hard voting routine on the same classifier at various (ROC) \n",
    "    thresholds. Number of thresholds must be odd therefore ties are assumed to be\n",
    "    impossible.\n",
    "    '''\n",
    "    # Getting confidence scores\n",
    "    if method == 'predict_proba':\n",
    "        conf_scores = clf.predict_proba(X_test)[:, 1].tolist()\n",
    "    else:\n",
    "        conf_scores = clf.decision_function(X_test).tolist()\n",
    "    conf_scores = pd.Series(data=conf_scores)\n",
    "        \n",
    "    # Getting prediction sets for each threshold\n",
    "    pred_sets = []\n",
    "    for threshold in thresholds:\n",
    "        thresholded_y_pred = np.where(conf_scores.values > threshold, 1, 0)\n",
    "        pred_sets.append(thresholded_y_pred.tolist())\n",
    "    pred_sets = pd.DataFrame(data=pred_sets)\n",
    "    pred_sets = pred_sets.T\n",
    "    pred_sets.columns = ['def', 'opt', 'min', 'tpr', 'fpr']\n",
    "    \n",
    "    # Summing all predictions for each row\n",
    "    pred_sets['sum'] = pred_sets.sum(axis=1)\n",
    "    \n",
    "    # Generating verdicts\n",
    "    sums = pred_sets['sum'].values.tolist()\n",
    "    pred_sets['V2'] = [1 if s > 1 else 0 for s in sums] # +ve if at least 2 +ve\n",
    "    pred_sets['V3'] = [1 if s > 2 else 0 for s in sums] # +ve if at least 3 +ve\n",
    "    pred_sets['V4'] = [1 if s > 3 else 0 for s in sums] # +ve if at least 4 +ve\n",
    "    \n",
    "    return pred_sets\n",
    "\n",
    "# Sample case\n",
    "me = METH['method'][0] # Method\n",
    "th = METH.iloc[0,1:-1].values.tolist() # Thresholds\n",
    "clf = METH['classifier'][0] # Trained classifier object\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_n, y, random_state=2018)\n",
    "\n",
    "print clf\n",
    "print th\n",
    "print me\n",
    "\n",
    "SCTR = THRESHOLD_VOTING(clf, th, me, X_test, y_test)\n",
    "print SCTR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T06:57:42.953000Z",
     "start_time": "2018-03-05T06:57:36.492000Z"
    },
    "code_folding": [
     0,
     18,
     20,
     22
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Summary\n",
      "          count   mean     std    min    25%    50%    75%  max\n",
      "distance    480  0.506  0.1182 0.3888 0.4356  0.464 0.5244    1\n",
      "cost        480 -188.4   42.78   -410   -189   -175   -164 -140\n",
      "accuracy    480 0.6636 0.07169  0.328   0.64   0.68  0.704 0.76\n",
      "fpr         480 0.3179  0.1536      0 0.2317 0.3049 0.3415    1\n",
      "tpr         480 0.6545  0.1616      0 0.5774 0.6786 0.7262    1\n",
      "\n",
      ">>> Top 10 with least distance, min cost and then best accuracy:\n",
      "                  Vx  distance  cost  accuracy    fpr    tpr                                   classifier\n",
      "SX_rbf_m_imb_cus  V3    0.3888  -163     0.732 0.2927  0.744  SVC(C=575.860892998151, cache_size=100, ...\n",
      "SL_l2h_m_imb_cus  V3     0.392  -161     0.724 0.2805 0.7262  LinearSVC(C=57.57069465681547, class_wei...\n",
      "SX_po2_m_bal_roc  V2    0.3928  -164     0.728 0.2927 0.7381  SVC(C=198.23168182801984, cache_size=100...\n",
      "SX_po2_m_imb_roc  V3    0.3981  -168     0.728 0.3049  0.744  SVC(C=0.03321495337607938, cache_size=10...\n",
      "SX_rbf_m_bal_cus  V2    0.4004  -163     0.716 0.2805 0.7143  SVC(C=198.23168182801984, cache_size=100...\n",
      "LR_l2l_m_imb_cus  V3    0.4004  -163     0.716 0.2805 0.7143  LogisticRegression(C=198.23168182801984,...\n",
      "LR_nwt_m_imb_cus  V3    0.4004  -163     0.716 0.2805 0.7143  LogisticRegression(C=198.23168182801984,...\n",
      "SX_rbf_m_bal_roc  V2    0.4004  -163     0.716 0.2805 0.7143  SVC(C=198.23168182801984, cache_size=100...\n",
      "RB_gin_u_imb_cus  V3    0.4008  -166      0.72 0.2927 0.7262  (DecisionTreeClassifier(class_weight=Non...\n",
      "RB_gin_u_imb_cus  V4    0.4011  -150     0.704 0.2317 0.6726  (DecisionTreeClassifier(class_weight=Non...\n"
     ]
    }
   ],
   "source": [
    "# --- Hard Voting Ensemble 1 ----------------------------------------------------\n",
    "\n",
    "# Stores results of hard voting ensemble 1\n",
    "HVE1 = pd.DataFrame(columns=['Vx', 'distance', 'cost', 'accuracy', 'fpr', 'tpr', \n",
    "                             'classifier'])\n",
    "\n",
    "# Stores verdicts for hard voting ensemble 1\n",
    "VER1 = []\n",
    "\n",
    "# Training and test sets\n",
    "X_train_n, X_test_n, y_train, y_test = train_test_split(X_n, y, random_state=2018)\n",
    "X_train_m, X_test_m, y_train, y_test = train_test_split(X_m, y, random_state=2018)\n",
    "X_train_u, X_test_u, y_train, y_test = train_test_split(X_u, y, random_state=2018)\n",
    "\n",
    "# Iterating through each clf in METH\n",
    "for i, name in enumerate(METH.index):\n",
    "    \n",
    "    # Feature scaling requirements for each set of classifiers\n",
    "    if name[7] == 'n': # Normalized scaling\n",
    "        X_train = X_train_n; X_test = X_test_n\n",
    "    elif name[7] == 'm': # MinMax scaling\n",
    "        X_train = X_train_m; X_test = X_test_m\n",
    "    else: # Unscaled features\n",
    "        X_train = X_train_u; X_test = X_test_u\n",
    "    \n",
    "    me = METH['method'][i] # Method\n",
    "    th = METH.iloc[i,1:-1].values.tolist() # Thresholds\n",
    "    clf = METH['classifier'][i] # Trained classifier object\n",
    "     \n",
    "    # Getting verdicts\n",
    "    verdicts = THRESHOLD_VOTING(clf, th, me, X_test, y_test)\n",
    "    VER1.append(verdicts)\n",
    "    \n",
    "    # Minimum required number of +ve votes to classify as +ve\n",
    "    n_pos_votes = ['V2','V3','V4']\n",
    "     \n",
    "    # Generating performance metrics\n",
    "    for pos_votes in n_pos_votes:\n",
    "        y_pred = verdicts[pos_votes].tolist()\n",
    "        cm = pd.DataFrame(metrics.confusion_matrix(y_test, y_pred),\n",
    "                          columns = ['pred -ve', 'pred +ve'],\n",
    "                          index = ['actual -ve', 'actual +ve'])\n",
    "        TP = cm.loc['actual +ve', 'pred +ve']\n",
    "        TN = cm.loc['actual -ve', 'pred -ve']\n",
    "        FN = cm.loc['actual +ve', 'pred -ve']\n",
    "        FP = cm.loc['actual -ve', 'pred +ve']\n",
    "        FPR = FP/float(FP+TN)\n",
    "        TPR = TP/float(TP+FN)\n",
    "        cost = -1*((FP*5)+FN)\n",
    "        acc = (TP+TN)/float(TP+TN+FP+FN)\n",
    "        \n",
    "        # Distance from best possible calssifier\n",
    "        d = ((1-TPR)**2 + FPR**2) ** 0.5\n",
    "\n",
    "        # Appending data\n",
    "        res = pd.DataFrame(data=[pos_votes, d, cost, acc, FPR, TPR, clf],\n",
    "                           columns=[name], index=['Vx', 'distance','cost', 'accuracy', \n",
    "                                                  'fpr', 'tpr', 'classifier']).T\n",
    "        HVE1 = pd.concat([HVE1, res], axis=0)\n",
    "\n",
    "# Creating verdicts dataframe (used in the next hard voting ensmble type)\n",
    "VER1 = pd.DataFrame(data=VER1, index=METH.index, columns=['verdict'])\n",
    "name = [] # Seperating VER1 classifier name and configuration names\n",
    "config = []\n",
    "for i in VER1.index:\n",
    "    name.append(i[:8])\n",
    "    config.append(i[9:])\n",
    "VER1 = VER1.reset_index(drop=True)\n",
    "VER1['name'] = name\n",
    "VER1['config'] = config\n",
    "VER1 = VER1[['name', 'config', 'verdict']]\n",
    "\n",
    "# Printing summary\n",
    "cols = ['distance','cost', 'accuracy', 'fpr', 'tpr'] \n",
    "HVE1[cols] = HVE1[cols].apply(pd.to_numeric)\n",
    "print '>>> Summary\\n{}\\n'.format(HVE1.iloc[:,1:-1].describe().T)\n",
    "print '>>> Top 10 with least distance, min cost and then best accuracy:'\n",
    "print HVE1.sort_values(['distance', 'cost', 'accuracy'], \n",
    "                        ascending=[True, False, False]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T08:25:00.380000Z",
     "start_time": "2018-03-05T08:24:59.685000Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Summary\n",
      "          count   mean     std     min    25%    50%    75%    max\n",
      "distance    120 0.4762 0.06422  0.3894  0.434 0.4512 0.4945 0.7563\n",
      "cost        120   -175   19.96    -271   -183 -171.5 -162.5   -143\n",
      "accuracy    120 0.6609 0.05199   0.464  0.635   0.68  0.696  0.744\n",
      "fpr         120 0.2751 0.08047 0.09756 0.2195 0.2805 0.3293 0.5366\n",
      "tpr         120 0.6297   0.108    0.25 0.5595 0.6577 0.7098 0.8571\n",
      "\n",
      ">>> Top 10 with least distance, min cost and then best accuracy:\n",
      "          Vx  distance  cost  accuracy    fpr    tpr\n",
      "SX_rbf_m  V3    0.3894  -151     0.716 0.2439 0.6964\n",
      "SX_rbf_m  V2    0.4004  -163     0.716 0.2805 0.7143\n",
      "SX_po2_m  V2    0.4113  -174      0.72 0.3171 0.7381\n",
      "SL_l2s_n  V2    0.4138  -172     0.712 0.3049 0.7202\n",
      "LR_l1l_n  V2    0.4151  -175     0.716 0.3171 0.7321\n",
      "LR_l1l_m  V2    0.4151  -175     0.716 0.3171 0.7321\n",
      "LR_l1s_n  V2     0.417  -178      0.72 0.3293  0.744\n",
      "LR_l2l_n  V3    0.4179  -157     0.692 0.2439 0.6607\n",
      "LR_l2s_n  V2    0.4189  -176     0.712 0.3171 0.7262\n",
      "LR_sag_n  V2    0.4189  -176     0.712 0.3171 0.7262\n"
     ]
    }
   ],
   "source": [
    "# --- Hard Voting Ensemble 2 ----------------------------------------------------\n",
    "\n",
    "# Stores performance metrics of hard voting ensemble 2\n",
    "HVE2 = pd.DataFrame(columns=['Vx', 'distance', 'cost', 'accuracy', 'fpr', 'tpr'])\n",
    "\n",
    "# Used to store hard voting ensemble 2 verdicts\n",
    "VER2 = pd.DataFrame(columns=['name', 'Vx', 'verdict'])\n",
    "\n",
    "# Getting all classifier names\n",
    "clf_unique_names = VER1['name'].unique()\n",
    "\n",
    "for name in clf_unique_names:\n",
    "    VER = VER1[VER1['name'] == name]\n",
    "    for V in ('V2', 'V3', 'V4'):\n",
    "        verdicts=pd.concat([VER[VER['config']=='bal_cus'].iloc[0,2][V],\n",
    "                            VER[VER['config']=='bal_roc'].iloc[0,2][V],\n",
    "                            VER[VER['config']=='imb_cus'].iloc[0,2][V],\n",
    "                            VER[VER['config']=='imb_roc'].iloc[0,2][V]], axis=1)\n",
    "        sums = verdicts.sum(axis=1).values.tolist()\n",
    "        verdicts['verdict'] = [1 if s > 2 else 0 for s in sums]\n",
    "        verdicts.columns = ['bal_cus', 'bal_roc', 'imb_cus', 'imb_roc', 'verdict']\n",
    "        \n",
    "        # Appending verdicts\n",
    "        res = pd.DataFrame(data=[name, V, verdicts],\n",
    "                           index=['name', 'Vx', 'verdict']).T\n",
    "        VER2 = pd.concat([VER2, res], axis=0)\n",
    "        \n",
    "        # Computing performance metrics\n",
    "        y_pred = verdicts['verdict'].tolist()\n",
    "        cm = pd.DataFrame(metrics.confusion_matrix(y_test, y_pred),\n",
    "                          columns = ['pred -ve', 'pred +ve'],\n",
    "                          index = ['actual -ve', 'actual +ve'])\n",
    "        TP = cm.loc['actual +ve', 'pred +ve']\n",
    "        TN = cm.loc['actual -ve', 'pred -ve']\n",
    "        FN = cm.loc['actual +ve', 'pred -ve']\n",
    "        FP = cm.loc['actual -ve', 'pred +ve']\n",
    "        FPR = FP/float(FP+TN)\n",
    "        TPR = TP/float(TP+FN)\n",
    "        cost = -1*((FP*5)+FN)\n",
    "        acc = (TP+TN)/float(TP+TN+FP+FN)\n",
    "        \n",
    "        # Distance from best possible calssifier\n",
    "        d = ((1-TPR)**2 + FPR**2) ** 0.5\n",
    "\n",
    "        # Appending data\n",
    "        res = pd.DataFrame(data=[V, d, cost, acc, FPR, TPR],\n",
    "                           columns=[name], index=['Vx', 'distance','cost',\n",
    "                                                  'accuracy', 'fpr', 'tpr']).T\n",
    "        HVE2 = pd.concat([HVE2, res], axis=0)\n",
    "\n",
    "# Reseting the index (just for consistency sake)\n",
    "VER2.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Printing summary\n",
    "cols = ['distance','cost', 'accuracy', 'fpr', 'tpr'] \n",
    "HVE2[cols] = HVE2[cols].apply(pd.to_numeric)\n",
    "print '>>> Summary\\n{}\\n'.format(HVE2.iloc[:,1:].describe().T)\n",
    "print '>>> Top 10 with least distance, min cost and then best accuracy:'\n",
    "print HVE2.sort_values(['distance', 'cost', 'accuracy'], \n",
    "                        ascending=[True, False, False]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T11:46:41.585000Z",
     "start_time": "2018-03-05T11:46:41.535000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  Vx                                      verdict\n",
      "0  SL_l1s_n  V2       bal_cus  bal_roc  imb_cus  imb_roc ...\n",
      "1  SL_l1s_n  V3       bal_cus  bal_roc  imb_cus  imb_roc ...\n",
      "2  SL_l1s_n  V4       bal_cus  bal_roc  imb_cus  imb_roc ...\n",
      "3  SL_l2s_n  V2       bal_cus  bal_roc  imb_cus  imb_roc ...\n",
      "4  SL_l2s_n  V3       bal_cus  bal_roc  imb_cus  imb_roc ...\n",
      "\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "Name: verdict, dtype: int64\n",
      "0      1\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "5      0\n",
      "6      1\n",
      "7      1\n",
      "8      1\n",
      "9      1\n",
      "10     0\n",
      "11     1\n",
      "12     0\n",
      "13     1\n",
      "14     0\n",
      "15     1\n",
      "16     1\n",
      "17     0\n",
      "18     1\n",
      "19     0\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     0\n",
      "24     1\n",
      "25     1\n",
      "26     1\n",
      "27     1\n",
      "28     1\n",
      "29     1\n",
      "      ..\n",
      "220    0\n",
      "221    1\n",
      "222    1\n",
      "223    0\n",
      "224    1\n",
      "225    1\n",
      "226    1\n",
      "227    1\n",
      "228    1\n",
      "229    1\n",
      "230    1\n",
      "231    0\n",
      "232    0\n",
      "233    1\n",
      "234    1\n",
      "235    1\n",
      "236    0\n",
      "237    1\n",
      "238    1\n",
      "239    0\n",
      "240    0\n",
      "241    1\n",
      "242    1\n",
      "243    0\n",
      "244    1\n",
      "245    0\n",
      "246    1\n",
      "247    1\n",
      "248    1\n",
      "249    0\n",
      "Name: verdict, Length: 250, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print VER2.head()\n",
    "print\n",
    "print VER2.iloc[0,2].iloc[:4,4]\n",
    "\n",
    "a = VER2[(VER2['name']=='SL_l1s_n') & (VER2['Vx']=='V2')]\n",
    "print a.iloc[0,2]['verdict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-05T11:54:44.378000Z",
     "start_time": "2018-03-05T11:54:44.128000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Summary\n",
      "          count   mean     std    min    25%    50%    75%    max\n",
      "distance     40 0.4538 0.03433 0.3894 0.4307 0.4473  0.469 0.5818\n",
      "cost         40 -174.3    13.3   -226   -179   -171   -166   -151\n",
      "accuracy     40 0.6712 0.02856  0.576  0.655  0.684  0.688  0.716\n",
      "fpr          40 0.2808 0.04054 0.2195 0.2561 0.2805 0.3049 0.4146\n",
      "tpr          40 0.6478 0.05147 0.5238 0.6205 0.6667 0.6845  0.744\n",
      "\n",
      ">>> Top 10 with least distance, min cost and then best accuracy:\n",
      "          distance  cost  accuracy    fpr    tpr\n",
      "SX_rbf_m    0.3894  -151     0.716 0.2439 0.6964\n",
      "LR_l2l_n    0.4179  -157     0.692 0.2439 0.6607\n",
      "SL_l2s_m    0.4221  -168     0.696 0.2805 0.6845\n",
      "LR_l1s_m    0.4261  -175       0.7 0.3049 0.7024\n",
      "SL_l2h_m    0.4266  -169     0.692 0.2805 0.6786\n",
      "LR_nwt_n    0.4279  -166     0.688 0.2683 0.6667\n",
      "LR_lbf_n    0.4279  -166     0.688 0.2683 0.6667\n",
      "LR_sag_n    0.4279  -166     0.688 0.2683 0.6667\n",
      "SL_l2s_n    0.4299  -163     0.684 0.2561 0.6548\n",
      "SL_l1s_m    0.4303  -173     0.692 0.2927 0.6845\n"
     ]
    }
   ],
   "source": [
    "# --- Hard Voting Ensemble 3 ----------------------------------------------------\n",
    "\n",
    "# Stores performance metrics of hard voting ensemble 2\n",
    "HVE3 = pd.DataFrame(columns=['distance', 'cost', 'accuracy', 'fpr', 'tpr'])\n",
    "\n",
    "# Used to store hard voting ensemble 2 verdicts\n",
    "VER3 = pd.DataFrame(columns=['name', 'verdict'])\n",
    "\n",
    "# Getting all classifier names\n",
    "clf_unique_names = VER2['name'].unique()\n",
    "\n",
    "for name in clf_unique_names:\n",
    "    VER = VER2[VER2['name'] == name]\n",
    "    verdicts=pd.concat([VER[VER['Vx']=='V2'].iloc[0,2]['verdict'],\n",
    "                        VER[VER['Vx']=='V3'].iloc[0,2]['verdict'],\n",
    "                        VER[VER['Vx']=='V4'].iloc[0,2]['verdict']], axis=1)\n",
    "    verdicts.columns = ['V2', 'V3', 'V4']\n",
    "    sums = verdicts.sum(axis=1).values.tolist()\n",
    "    verdicts['verdict'] = [1 if s > 1 else 0 for s in sums]\n",
    "    \n",
    "    # Appending verdicts\n",
    "    res = pd.DataFrame(data=[name, verdicts], index=['name', 'verdict']).T\n",
    "    VER3 = pd.concat([VER3, res], axis=0)\n",
    "    \n",
    "    # Computing performance metrics\n",
    "    y_pred = verdicts['verdict'].tolist()\n",
    "    cm = pd.DataFrame(metrics.confusion_matrix(y_test, y_pred),\n",
    "                      columns = ['pred -ve', 'pred +ve'],\n",
    "                      index = ['actual -ve', 'actual +ve'])\n",
    "    TP = cm.loc['actual +ve', 'pred +ve']\n",
    "    TN = cm.loc['actual -ve', 'pred -ve']\n",
    "    FN = cm.loc['actual +ve', 'pred -ve']\n",
    "    FP = cm.loc['actual -ve', 'pred +ve']\n",
    "    FPR = FP/float(FP+TN)\n",
    "    TPR = TP/float(TP+FN)\n",
    "    cost = -1*((FP*5)+FN)\n",
    "    acc = (TP+TN)/float(TP+TN+FP+FN)\n",
    "        \n",
    "    # Distance from best possible calssifier\n",
    "    d = ((1-TPR)**2 + FPR**2) ** 0.5\n",
    "\n",
    "    # Appending data\n",
    "    res = pd.DataFrame(data=[d, cost, acc, FPR, TPR], columns=[name], \n",
    "                       index=['distance', 'cost', 'accuracy', 'fpr', 'tpr']).T\n",
    "    HVE3 = pd.concat([HVE3, res], axis=0)\n",
    "\n",
    "# Reseting the index (just for consistency sake)\n",
    "VER3.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Printing summary\n",
    "cols = ['distance','cost', 'accuracy', 'fpr', 'tpr'] \n",
    "HVE3[cols] = HVE3[cols].apply(pd.to_numeric)\n",
    "print '>>> Summary\\n{}\\n'.format(HVE3.describe().T)\n",
    "print '>>> Top 10 with least distance, min cost and then best accuracy:'\n",
    "print HVE3.sort_values(['distance', 'cost', 'accuracy'], \n",
    "                        ascending=[True, False, False]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
